# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['cv_aid', 'tests']

package_data = \
{'': ['*']}

modules = \
['scripts']
install_requires = \
['cmake>=3.22.1,<4.0.0',
 'deepstack-sdk>=0.2.1,<0.3.0',
 'dlib>=19.22.1,<20.0.0',
 'filetype>=1.0.9,<2.0.0',
 'numpy>=1.21,<2.0',
 'opencv-python>=4.1.0,<5.0.0',
 'requests>=2.27.1,<3.0.0',
 'tqdm>=4.62.3,<5.0.0']

entry_points = \
{'console_scripts': ['test = scripts:test']}

setup_kwargs = {
    'name': 'cv-aid',
    'version': '1.0.0',
    'description': 'CV Aid is a set of helpers for computer vision tasks.',
    'long_description': '# cv-aid\n\nCV Aid is a set of helpers of computer vision tasks.\n\n## Installation\n\n`pip install cv-aid`\n\n### From source\n\n```\ngit clone https://github.com/khalidelboray/cv-aid\ncd cv-aid\npoetry install\npoetry run python setup.py install\n```\n\n## Tests\n\n`poetry run test`\n\nall tests are in `tests/` directory.\n\n## Examples\n\n- Basic Frame Functions\n\n    ```python\n    from cv_aid import Frame\n\n    frame = Frame.load(\'/path/to/image.jpg\')\n    # or\n    import cv2\n    frame = Frame(cv2.imread(\'/path/to/image.jpg\'))\n\n    # Grayscale image\n    gray = frame.gray()\n\n    # Resize image\n    small = frame.resize(width=100, height=100)\n\n    # Crop image\n    cropped = frame.crop(x=100, y=100, width=100, height=100)\n\n    # All methods return a new Frame object, so you can chain them\n    new_frame = frame.resize(width=100, height=100).crop(x=100, y=100, width=100, height=100)\n\n    # Save image\n    frame.save(\'/path/to/image.jpg\')\n    ```\n\n- Basic Video Functions\n\n    ```python\n    from cv_aid import VideoStream, Frame\n    import cv2\n    import numpy as np\n\n\n    def on_frame(frame: Frame) -> Frame:\n        """\n        A function that is called when a frame is read from the video stream.\n\n        :param frame: The frame that was read.\n        :return: The frame that was read.\n        """\n        orig = frame\n        canny = frame.gray().canny(50, 100)\n        line_image = Frame(np.copy(orig.frame) * 0)\n        lines = cv2.HoughLinesP(\n            canny.frame, 1, np.pi / 180, 50, np.array([]), minLineLength=10, maxLineGap=5\n        )\n        if lines is not None:\n            for line in lines:\n                line = line[0]\n                line_image = line_image.line(\n                    (line[0], line[1]), (line[2], line[3]), (0, 255, 0), 3\n                )\n        lines_edges = cv2.addWeighted(orig.frame, 0.8, line_image.frame, 1, 1)\n        return Frame(lines_edges)\n\n\n    stream = VideoStream(src=0, on_frame=on_frame).start()\n    stream.start_window()\n    ```\n\n    *Output Demo:*\n\n    ![Code Window](https://raw.githubusercontent.com/khalidelboray/cv-aid/master/images/stream.png)\n\n- Haar Cascade Functions\n\n    ```python\n    from cv_aid import VideoStream, Frame\n\n    def on_frame(frame: Frame) -> Frame:\n        """\n        A function that is called when a frame is read from the video stream.\n\n        :param frame: The frame that was read.\n        :return: The frame that was read.\n        """\n        boxes = frame.haarcascades.detect_faces(frame.frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n        frame = frame.boxes(boxes, color=(0, 255, 0))\n        return frame\n\n\n    if __name__ == "__main__":\n\n        stream = VideoStream(src=0, on_frame=on_frame).start()\n        stream.start_window()\n    ```\n\n    *Output Demo:*\n\n    ![haarcascade Window](https://raw.githubusercontent.com/khalidelboray/cv-aid/master/images/haarcascades.png)\n\n- Tourch Hub (Yolov5)\n\n    ```python\n    from cv_aid import VideoStream, Frame\n    import torch\n\n    model = torch.hub.load(\'ultralytics/yolov5\', \'yolov5s\')\n\n    def on_frame(frame: Frame) -> Frame:\n        """\n        A function that is called when a frame is read from the video stream.\n\n        :param frame: The frame that was read.\n        :return: The frame that was read.\n        """\n        results = model(frame.frame)\n        results.display(render=True)\n        frame = Frame(results.imgs[0])    \n        return frame\n\n\n    if __name__ == "__main__":\n        \n        stream = VideoStream(src=0, on_frame=on_frame).start()\n        stream.start_window()\n    ```\n\n    ![torch yolov5](https://raw.githubusercontent.com/khalidelboray/cv-aid/master/images/torch_yolo.png)\n\n- Dlib (`Download model`)\n\n    ```python\n    from cv_aid._dlib import Dlib\n    saved_model = Dlib.download_landmark_detector(path=\'/dir/to/download/model/at/\')\n    dlib = Dlib(landmark_predictor_path=saved_model)\n\n    face_recognetion_model = Dlib.download_face_recognition_model_v1(path=\'/dir/to/download/model/at/\')\n    ```\n\n- Dlib (Face landmark)\n\n    `Give it a try!`\n\n    ```python\n    # pylint: disable=C0103\n\n    import math\n\n    import cv2\n    import numpy as np\n    from skimage.draw import disk, polygon, set_color\n\n    from cv_aid import Frame, VideoStream\n\n    RIGHT_EYE_POINTS = list(range(36, 42))\n    LEFT_EYE_POINTS = list(range(42, 48))\n\n\n    def get_poly_data(desired, landmarks, shape):\n        points = []\n        for i in desired:\n            points.append((landmarks.part(i).x, landmarks.part(i).y))\n        points = np.array(points, dtype=np.int32)\n        rr, cc = polygon(points[:, 1], points[:, 0], shape)\n        return points, rr, cc\n\n\n    def on_frame(frame: Frame) -> Frame:\n        """\n        A function that is called when a frame is read from the video stream.\n\n        :param frame: The frame that was read.\n        :return: The frame that was read.\n        """\n\n        faces = frame.dlib.detect_faces(frame.frame)\n        for face in faces:\n            face_landmarks = frame.dlib.detect_landmarks(frame.frame, face)\n            left_eye, *_ = get_poly_data(LEFT_EYE_POINTS, face_landmarks, frame.shape)\n            right_eye, *_ = get_poly_data(RIGHT_EYE_POINTS, face_landmarks, frame.shape)\n\n            left_eye_center = left_eye.mean(axis=0).astype("int")\n            right_eye_center = right_eye.mean(axis=0).astype("int")\n            left_eye_radius = (\n                int(\n                    math.sqrt(\n                        (left_eye[3][0] - left_eye[0][0]) ** 2\n                        + (left_eye[3][1] - left_eye[0][1]) ** 2\n                    )\n                )\n                - 10\n            )\n            right_eye_radius = (\n                int(\n                    math.sqrt(\n                        (right_eye[3][0] - right_eye[0][0]) ** 2\n                        + (right_eye[3][1] - right_eye[0][1]) ** 2\n                    )\n                )\n                - 10\n            )\n            frame = (\n                # Glasses connection line\n                frame.line(\n                    (left_eye_center[0] - left_eye_radius, left_eye_center[1]),\n                    (right_eye_center[0] + right_eye_radius, right_eye_center[1]),\n                    (0, 0, 0),\n                    4,\n                )\n                # Glasses circle 1 *Border*\n                .circle(\n                    left_eye_center,\n                    left_eye_radius,\n                    (0, 0, 0),\n                    4,\n                )\n                # Glasses circle 1\n                .circle(\n                    left_eye_center,\n                    left_eye_radius,\n                    (0, 0, 255),\n                    2,\n                )\n                # Glasses circle 2 *Border*\n                .circle(\n                    right_eye_center,\n                    right_eye_radius,\n                    (0, 0, 0),\n                    4,\n                )\n                # Glasses circle 2\n                .circle(\n                    right_eye_center,\n                    right_eye_radius,\n                    (0, 0, 255),\n                    2,\n                )\n                # Ears connection line 1\n                .line(\n                    (face_landmarks.part(0).x, face_landmarks.part(0).y),\n                    (right_eye_center[0] - right_eye_radius, right_eye_center[1]),\n                    (0, 0, 255),\n                    2,\n                )\n                # Ears connection line 1\n                .line(\n                    (face_landmarks.part(16).x, face_landmarks.part(16).y),\n                    (left_eye_center[0] + left_eye_radius, left_eye_center[1]),\n                    (0, 0, 255),\n                    2,\n                )\n            )\n            # Overlay the frame with the image of the glasses colored in transparent black\n            overlay = frame.frame.copy()\n            alpha = 0.5\n            # Get first circle rows and columns (pixel coordinates)\n            rr, cc = disk(right_eye_center[::-1], right_eye_radius)\n            # Set the color of the circle\n            set_color(overlay, (rr, cc), (0, 0, 0))\n\n            # Get second circle rows and columns (pixel coordinates)\n            rr, cc = disk(left_eye_center[::-1], left_eye_radius)\n            # Set the color of the circle\n            set_color(overlay, (rr, cc), (0, 0, 0))\n\n            # Overlay the image with the overlay image\n            frame.frame = cv2.addWeighted(overlay, alpha, frame.frame, 1 - alpha, 0)\n\n        return frame\n\n\n    if __name__ == "__main__":\n\n        stream = VideoStream(src=0, on_frame=on_frame).start()\n        stream.start_window()\n\n    ```\n',
    'author': 'Khalid Mohamed Elborai',
    'author_email': 'accnew820@gmail.com',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://github.com/khalidelboray/cv-aid',
    'packages': packages,
    'package_data': package_data,
    'py_modules': modules,
    'install_requires': install_requires,
    'entry_points': entry_points,
    'python_requires': '>=3.8,<4.0',
}


setup(**setup_kwargs)
