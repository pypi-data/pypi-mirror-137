{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confidential-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "increasing-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "occupied-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from pathlib import Path\n",
    "from roheboam.engine.utils.convenience import is_notebook, run_shell_command\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "ROOT_PATH = Path(globals()[\"_dh\"][0]) if is_notebook() else Path(__file__).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "blind-fifth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/roheboam-cuda/lib/python3.7/site-packages/contracts/library/miscellaneous_aliases.py:19: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  m_new_contract('Container', ist(collections.Container))\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "from roheboam.engine.integrations.dvc import DVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-provision",
   "metadata": {},
   "source": [
    "#### 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aboriginal-emperor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/roheboam-cuda/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating git remote for application (this would usually be hosted in the cloud e.g. Github)\n",
      "git init --bare /tmp/tmppp14pdmm\n",
      "hint: Using 'master' as the name for the initial branch. This default branch name\n",
      "hint: is subject to change. To configure the initial branch name to use in all\n",
      "hint: of your new repositories, which will suppress this warning, call:\n",
      "hint: \n",
      "hint: \tgit config --global init.defaultBranch <name>\n",
      "hint: \n",
      "hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\n",
      "hint: 'development'. The just-created branch can be renamed via this command:\n",
      "hint: \n",
      "hint: \tgit branch -m <name>\n",
      "Initialized empty Git repository in /tmp/tmppp14pdmm/\n",
      "Creating git for application\n",
      "git init /tmp/tmp8fkr3ksl\n",
      "hint: Using 'master' as the name for the initial branch. This default branch name\n",
      "hint: is subject to change. To configure the initial branch name to use in all\n",
      "hint: of your new repositories, which will suppress this warning, call:\n",
      "hint: \n",
      "hint: \tgit config --global init.defaultBranch <name>\n",
      "hint: \n",
      "hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\n",
      "hint: 'development'. The just-created branch can be renamed via this command:\n",
      "hint: \n",
      "hint: \tgit branch -m <name>\n",
      "Initialized empty Git repository in /tmp/tmp8fkr3ksl/.git/\n",
      "cd /tmp/tmp8fkr3ksl && git remote add origin /tmp/tmppp14pdmm\n",
      "Creating DVC remote (this would usually be hosted in the cloud e.g. S3, Azure Blob, Google Cloud Storage)\n",
      "dvc --cd /tmp/tmp8fkr3ksl init\n",
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                     |\n",
      "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
      "|     Read the analytics documentation (and how to opt-out) here:     |\n",
      "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
      "|                                                                     |\n",
      "+---------------------------------------------------------------------+\n",
      "\n",
      "What's next?\n",
      "------------\n",
      "- Check out the documentation: <https://dvc.org/doc>\n",
      "- Get help and share ideas: <https://dvc.org/chat>\n",
      "- Star us on GitHub: <https://github.com/iterative/dvc>\n",
      "dvc --cd /tmp/tmp8fkr3ksl install\n",
      "dvc --cd /tmp/tmp8fkr3ksl remote add -d local_remote /tmp/tmpmj8geip_\n",
      "Setting 'local_remote' as a default remote.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Creating git remote for application (this would usually be hosted in the cloud e.g. Github)\"\n",
    ")\n",
    "git_remote = TemporaryDirectory()\n",
    "run_shell_command(f\"git init --bare {git_remote.name}\")\n",
    "\n",
    "print(\"Creating git for application\")\n",
    "app_dir = TemporaryDirectory()\n",
    "run_shell_command(f\"git init {app_dir.name}\")\n",
    "run_shell_command(f\"cd {app_dir.name} && git remote add origin {git_remote.name}\")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Creating DVC remote (this would usually be hosted in the cloud e.g. S3, Azure Blob, Google Cloud Storage)\"\n",
    ")\n",
    "dvc = DVC()\n",
    "dvc_remote = TemporaryDirectory()\n",
    "\n",
    "dvc.init(dvc_run_path=app_dir.name)\n",
    "dvc.install(dvc_run_path=app_dir.name)\n",
    "dvc.add_remote(\n",
    "    remote_name=\"local_remote\",\n",
    "    remote_path=dvc_remote.name,\n",
    "    dvc_run_path=app_dir.name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-familiar",
   "metadata": {},
   "source": [
    "#### 1. Track existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "scheduled-freight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying data to application directory to mock existing data\n",
      "Track data\n",
      "dvc --cd /tmp/tmp8fkr3ksl add /tmp/tmp8fkr3ksl/data/generated_samples --file /tmp/tmp8fkr3ksl/data/generated_samples.dvc\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "    git add data/.gitignore data/generated_samples.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "print(\"Copying data to application directory to mock existing data\")\n",
    "shutil.copytree(\n",
    "    ROOT_PATH / \"data\" / \"generated_samples\" / \"sample_1\",\n",
    "    Path(app_dir.name) / \"data\" / \"generated_samples\" / \"sample_1\",\n",
    ")\n",
    "shutil.copytree(\n",
    "    ROOT_PATH / \"data\" / \"generated_samples\" / \"sample_2\",\n",
    "    Path(app_dir.name) / \"data\" / \"generated_samples\" / \"sample_2\",\n",
    ")\n",
    "\n",
    "print(\"Track data\")\n",
    "dvc.add(\n",
    "    add_path=Path(app_dir.name) / \"data\" / \"generated_samples\",\n",
    "    dvc_output_path=Path(app_dir.name) / \"data\" / \"generated_samples.dvc\",\n",
    "    dvc_run_path=Path(app_dir.name),\n",
    ")\n",
    "assert (Path(app_dir.name) / \"data\" / \"generated_samples.dvc\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "arctic-vacuum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs:\n",
      "- md5: 005b0633ea0f5b53e2dbf3cdbae70261.dir\n",
      "  size: 3587101\n",
      "  nfiles: 2\n",
      "  path: generated_samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((Path(app_dir.name) / \"data\" / \"generated_samples.dvc\").open(\"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-headset",
   "metadata": {},
   "source": [
    "#### 2. Train with config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "jewish-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup mock training_inputs folder, input config files and training_outputs folder\n",
      "dvc --cd /tmp/tmp8fkr3ksl run -n train -d training_inputs -d data/generated_samples -o training_outputs python train.py\n",
      "Running stage 'train':\n",
      "> python train.py\n",
      "Creating 'dvc.yaml'\n",
      "Adding stage 'train' in 'dvc.yaml'\n",
      "Generating lock file 'dvc.lock'\n",
      "Updating lock file 'dvc.lock'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "    git add .gitignore dvc.yaml dvc.lock\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "print(\n",
    "    \"Setup mock training_inputs folder, input config files and training_outputs folder\"\n",
    ")\n",
    "CONFIG_FILE_PATH = Path(app_dir.name) / \"training_inputs\" / \"configs\"\n",
    "CONFIG_FILE_PATH.mkdir(exist_ok=True, parents=True)\n",
    "config = {\"model_name\": \"model_1\"}\n",
    "json.dump(\n",
    "    config,\n",
    "    open(\n",
    "        Path(app_dir.name) / \"training_inputs\" / \"configs\" / \"config.json\",\n",
    "        \"w\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "MODEL_OUTPUT_PATH = Path(app_dir.name) / \"training_outputs\"\n",
    "TRAIN_FILE = f\"\"\"\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "config = json.load(open(\"{app_dir.name}/training_inputs/configs/config.json\", \"r\"))\n",
    "training_data = [str(p) for p in (Path(\"{app_dir.name}\") / \"data\" / \"generated_samples\").glob(\"*\")]\n",
    "(Path.cwd() / \"training_outputs\").mkdir(exist_ok=True, parents=True)\n",
    "pickle.dump(dict(model_name=config[\"model_name\"], training_data=training_data), open(f\"{MODEL_OUTPUT_PATH}/model.p\", \"wb\"))\n",
    "\"\"\"\n",
    "with (Path(app_dir.name) / \"train.py\").open(\"w\") as f:\n",
    "    f.write(TRAIN_FILE)\n",
    "\n",
    "# Run with DVC\n",
    "dvc.run(\n",
    "    \"train\",\n",
    "    f\"python train.py\",\n",
    "    dependency_paths=[\"training_inputs\", \"data/generated_samples\"],\n",
    "    output_paths=[\"training_outputs\"],\n",
    "    dvc_run_path=Path(app_dir.name),\n",
    ")\n",
    "\n",
    "# Test with assertions\n",
    "model = pickle.load(open(MODEL_OUTPUT_PATH / \"model.p\", \"rb\"))\n",
    "model[\"model_name\"] == \"model_1\"\n",
    "assert len(model[\"training_data\"]) == 2\n",
    "assert (MODEL_OUTPUT_PATH / \"model.p\").exists()\n",
    "assert (Path(app_dir.name) / \"dvc.lock\").exists()\n",
    "assert (Path(app_dir.name) / \"dvc.yaml\").exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-liverpool",
   "metadata": {},
   "source": [
    "#### 3. Change config and use DVC repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unauthorized-destination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dvc --cd /tmp/tmp8fkr3ksl repro\n",
      "'data/generated_samples.dvc' didn't change, skipping\n",
      "Running stage 'train':\n",
      "> python train.py\n",
      "Updating lock file 'dvc.lock'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "    git add dvc.lock\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Change config file\n",
    "config = {\"model_name\": \"model_1_changed\"}\n",
    "json.dump(config, open(CONFIG_FILE_PATH / \"config.json\", \"w\"))\n",
    "\n",
    "# Repro\n",
    "dvc.repro(dvc_run_path=Path(app_dir.name))\n",
    "\n",
    "# See if script was run\n",
    "model = pickle.load(open(MODEL_OUTPUT_PATH / \"model.p\", \"rb\"))\n",
    "model[\"model_name\"] == \"model_1_changed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-album",
   "metadata": {},
   "source": [
    "#### 4. Update data and use DVC repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accepting-macro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dvc --cd /tmp/tmp8fkr3ksl repro\n",
      "Verifying data sources in stage: 'data/generated_samples.dvc'\n",
      "\n",
      "Running stage 'train':\n",
      "> python train.py\n",
      "Updating lock file 'dvc.lock'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "    git add data/generated_samples.dvc dvc.lock\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Change config file\n",
    "shutil.copytree(\n",
    "    ROOT_PATH / \"data\" / \"generated_samples\" / \"sample_3\",\n",
    "    Path(app_dir.name) / \"data\" / \"generated_samples\" / \"sample_3\",\n",
    ")\n",
    "\n",
    "# Repro\n",
    "dvc.repro(dvc_run_path=Path(app_dir.name))\n",
    "\n",
    "# See if script was run\n",
    "model = pickle.load(open(MODEL_OUTPUT_PATH / \"model.p\", \"rb\"))\n",
    "assert model[\"model_name\"] == \"model_1_changed\"\n",
    "assert len(model[\"training_data\"]) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-manitoba",
   "metadata": {},
   "source": [
    "#### 5. Add everything and push to remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "responsible-malta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice here that all the data that has been added by DVC is ignored\n",
      "cd /tmp/tmp8fkr3ksl && git add .\n",
      "cd /tmp/tmp8fkr3ksl && git commit -m 'initial commit'\n",
      "Data and pipelines are up to date.\n",
      "[master (root-commit) 1ade05e] initial commit\n",
      " 16 files changed, 561 insertions(+)\n",
      " create mode 100644 .dvc/.gitignore\n",
      " create mode 100644 .dvc/config\n",
      " create mode 100644 .dvc/plots/confusion.json\n",
      " create mode 100644 .dvc/plots/confusion_normalized.json\n",
      " create mode 100644 .dvc/plots/linear.json\n",
      " create mode 100644 .dvc/plots/scatter.json\n",
      " create mode 100644 .dvc/plots/simple.json\n",
      " create mode 100644 .dvc/plots/smooth.json\n",
      " create mode 100644 .dvcignore\n",
      " create mode 100644 .gitignore\n",
      " create mode 100644 data/.gitignore\n",
      " create mode 100644 data/generated_samples.dvc\n",
      " create mode 100644 dvc.lock\n",
      " create mode 100644 dvc.yaml\n",
      " create mode 100644 train.py\n",
      " create mode 100644 training_inputs/configs/config.json\n",
      "cd /tmp/tmp8fkr3ksl && git push origin master\n",
      "6 files pushed\n",
      "To /tmp/tmppp14pdmm\n",
      " * [new branch]      master -> master\n"
     ]
    }
   ],
   "source": [
    "print(\"Notice here that all the data that has been added by DVC is ignored\")\n",
    "run_shell_command(f\"cd {app_dir.name} && git add .\")\n",
    "run_shell_command(f\"cd {app_dir.name} && git commit -m 'initial commit'\")\n",
    "run_shell_command(f\"cd {app_dir.name} && git push origin master\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "closing-consultancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cd /tmp/tmp8fkr3ksl && du -sh --\n",
      "9.1M\t.\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "run_shell_command(f\"cd {app_dir.name} && du -sh --\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "exceptional-berlin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /tmp/tmp8fkr3ksl && du -ah | sort -h | tail -n 5\n",
      "4.2M\t./data/generated_samples\n",
      "4.3M\t./.dvc/cache\n",
      "4.3M\t./data\n",
      "4.5M\t./.dvc\n",
      "9.1M\t.\n"
     ]
    }
   ],
   "source": [
    "# Get the 5 largest files\n",
    "run_shell_command(f\"cd {app_dir.name} && du -ah | sort -h | tail -n 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rough-interview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /tmp/tmp8fkr3ksl && git remote -v\n",
      "origin\t/tmp/tmppp14pdmm (fetch)\n",
      "origin\t/tmp/tmppp14pdmm (push)\n"
     ]
    }
   ],
   "source": [
    "run_shell_command(f\"cd {app_dir.name} && git remote -v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "limiting-render",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /tmp/tmpmj8geip_ && du -sh --\n",
      "4.3M\t.\n"
     ]
    }
   ],
   "source": [
    "run_shell_command(f\"cd {dvc_remote.name} && du -sh --\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "signal-nylon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /tmp/tmppp14pdmm && du -sh --\n",
      "296K\t.\n"
     ]
    }
   ],
   "source": [
    "run_shell_command(f\"cd {git_remote.name} && du -sh --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-negative",
   "metadata": {},
   "source": [
    "#### 6. Pull down only the model file (useful during CI when we need to test the model and deploy it, no need for data files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "productive-seven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clone down our model file\n",
      "cd /tmp/tmpuu9o38nq && git clone /tmp/tmppp14pdmm\n",
      "Cloning into 'tmppp14pdmm'...\n",
      "done.\n",
      "Check we don't have our model or data files\n",
      "cd /tmp/tmpuu9o38nq/tmppp14pdmm && du -sh -- *\n",
      "12K\tdata\n",
      "4.0K\tdvc.lock\n",
      "4.0K\tdvc.yaml\n",
      "4.0K\ttrain.py\n",
      "12K\ttraining_inputs\n",
      "dvc --cd /tmp/tmpuu9o38nq/tmppp14pdmm pull train\n",
      "A       training_outputs/\n",
      "1 file added and 1 file fetched\n",
      "Check what has changed, not that even though the data folder exists, not data resides in it\n",
      "cd /tmp/tmpuu9o38nq/tmppp14pdmm && du -sh -- *\n",
      "12K\tdata\n",
      "4.0K\tdvc.lock\n",
      "4.0K\tdvc.yaml\n",
      "4.0K\ttrain.py\n",
      "12K\ttraining_inputs\n",
      "8.0K\ttraining_outputs\n",
      "Check that the model file exists\n",
      "cd /tmp/tmpuu9o38nq/tmppp14pdmm/training_outputs && du -sh -- *\n",
      "4.0K\tmodel.p\n"
     ]
    }
   ],
   "source": [
    "print(\"Clone down our model file\")\n",
    "tmp_dir_ci_env = TemporaryDirectory()\n",
    "run_shell_command(f\"cd {tmp_dir_ci_env.name} && git clone {git_remote.name}\")\n",
    "cloned_project_path = f\"{tmp_dir_ci_env.name}/{Path(git_remote.name).stem}\"\n",
    "\n",
    "print(\"Check we don't have our model or data files\")\n",
    "run_shell_command(f\"cd {cloned_project_path} && du -sh -- *\")\n",
    "dvc.pull(stage=\"train\", dvc_run_path=cloned_project_path)\n",
    "\n",
    "print(\n",
    "    \"Check what has changed, not that even though the data folder exists, not data resides in it\"\n",
    ")\n",
    "run_shell_command(f\"cd {cloned_project_path} && du -sh -- *\")\n",
    "\n",
    "print(\"Check that the model file exists\")\n",
    "run_shell_command(f\"cd {cloned_project_path}/training_outputs && du -sh -- *\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-reducing",
   "metadata": {},
   "source": [
    "#### 7. Mimic developer environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hazardous-provincial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clone down all files needed for development\n",
      "cd /tmp/tmpz67_mmwv && git clone /tmp/tmppp14pdmm\n",
      "Cloning into 'tmppp14pdmm'...\n",
      "done.\n",
      "Check the files before DVC pull\n",
      "cd /tmp/tmpz67_mmwv/tmppp14pdmm && du -sh -- *\n",
      "12K\tdata\n",
      "4.0K\tdvc.lock\n",
      "4.0K\tdvc.yaml\n",
      "4.0K\ttrain.py\n",
      "12K\ttraining_inputs\n",
      "Check the files after DVC pull\n",
      "dvc --cd /tmp/tmpz67_mmwv/tmppp14pdmm pull\n",
      "A       training_outputs/\n",
      "A       data/generated_samples/\n",
      "2 files added and 4 files fetched\n",
      "cd /tmp/tmpz67_mmwv/tmppp14pdmm && du -sh -- *\n",
      "4.3M\tdata\n",
      "4.0K\tdvc.lock\n",
      "4.0K\tdvc.yaml\n",
      "4.0K\ttrain.py\n",
      "12K\ttraining_inputs\n",
      "8.0K\ttraining_outputs\n"
     ]
    }
   ],
   "source": [
    "print(\"Clone down all files needed for development\")\n",
    "tmp_dir_dev_environment = TemporaryDirectory()\n",
    "run_shell_command(f\"cd {tmp_dir_dev_environment.name} && git clone {git_remote.name}\")\n",
    "cloned_project_path = f\"{tmp_dir_dev_environment.name}/{Path(git_remote.name).stem}\"\n",
    "\n",
    "print(\"Check the files before DVC pull\")\n",
    "run_shell_command(f\"cd {cloned_project_path} && du -sh -- *\")\n",
    "\n",
    "print(\"Check the files after DVC pull\")\n",
    "dvc.pull(dvc_run_path=cloned_project_path)\n",
    "run_shell_command(f\"cd {cloned_project_path} && du -sh -- *\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
