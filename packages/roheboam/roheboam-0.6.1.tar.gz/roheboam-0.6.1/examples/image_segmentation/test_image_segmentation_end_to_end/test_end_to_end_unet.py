# AUTOGENERATED! DO NOT EDIT! File to edit: test_end_to_end_unet.ipynb (unless otherwise specified).

__all__ = [
    "ROOT_PATH",
    "GPU_ID",
    "use_berlin_segmentation_test",
    "config",
    "pipeline",
    "module",
    "trainer",
    "recorder",
    "before_train_module_weights",
    "after_train_module_weights",
    "checkpoint_callback",
    "checkpoint_path",
    "inference_pipeline",
    "inference_module",
    "inference_trainer",
    "before_load_inference_module_weights",
    "pl_checkpoint",
    "after_load_inference_module_weights",
    "test_samples",
    "test_dataset",
    "test_dataloader",
    "trainer_predictions",
    "inference_trainer_predictions",
    "mlflow_save_path",
    "test_samples_json",
    "images_df",
    "mlflow_model",
    "mlflow_predictions",
    "test_samples_with_paths_json",
    "images_df",
    "mlflow_model",
    "mlflow_predictions",
    "source_path",
    "model_image",
    "port",
    "container",
]

import json

# Cell
import os
import random
from pathlib import Path

import cloudpickle
import mlflow
import numpy as np
import pandas as pd
import torch
from pytorch_lightning.utilities.cloud_io import load as pl_load

from roheboam.engine import get_toolbox_lookup
from roheboam.engine.integrations.mlflow.loading import load_mlflow_pyfunc_model
from roheboam.engine.integrations.mlflow.saving import save_mlflow_pyfunc_model
from roheboam.engine.pipeline import Pipeline
from roheboam.engine.pipeline.config_loader import load_config_from_paths
from roheboam.engine.pipeline.constants import VARIABLE_KEY
from roheboam.engine.utils.convenience import is_notebook
from roheboam.engine.utils.saving import save_to_temporary_file
from roheboam.engine.utils.testing import all_methods_in_callback_handler_are_called, arrays_are_same, copy_and_flatten_model_weights
from roheboam.engine.vision.tasks.image_segmentation.data import create_segmentation_sample
from roheboam.engine.vision.tasks.image_segmentation.deployment import MLFlowPyfuncImageSegmentationModel

# Cell
ROOT_PATH = Path(globals()["_dh"][0]) if is_notebook() else Path(__file__).parent.parent
GPU_ID = 1

# Cell
def use_berlin_segmentation_test(config):
    config[VARIABLE_KEY]["train_image_path"] = str(ROOT_PATH / "data" / "berlin_segmentation_test" / "train" / "images")
    config[VARIABLE_KEY]["train_mask_path"] = str(ROOT_PATH / "data" / "berlin_segmentation_test" / "train" / "masks")
    config[VARIABLE_KEY]["test_image_path"] = str(ROOT_PATH / "data" / "berlin_segmentation_test" / "test" / "images")
    config[VARIABLE_KEY]["test_mask_path"] = str(ROOT_PATH / "data" / "berlin_segmentation_test" / "test" / "masks")
    config[VARIABLE_KEY]["image_glob_string"] = "*.jpg"
    config[VARIABLE_KEY]["mask_glob_string"] = "*.png"
    config[VARIABLE_KEY]["max_epochs"] = 1
    config[VARIABLE_KEY]["train_num_workers"] = 0
    config[VARIABLE_KEY]["val_num_workers"] = 0
    config[VARIABLE_KEY]["test_num_workers"] = 0
    config[VARIABLE_KEY]["gpus"] = GPU_ID if torch.cuda.is_available() else None
    return config, (12, 8)


# Cell
config = load_config_from_paths(
    [
        ROOT_PATH / "configs/augmentation.yml",
        ROOT_PATH / "configs/callbacks.yml",
        ROOT_PATH / "configs/dataset.yml",
        ROOT_PATH / "configs/data_setup.yml",
        ROOT_PATH / "configs/loss.yml",
        ROOT_PATH / "configs/model.yml",
        ROOT_PATH / "configs/optimizer.yml",
        ROOT_PATH / "configs/trainer.yml",
        ROOT_PATH / "configs/transformations.yml",
        ROOT_PATH / "configs/variables.yml",
        ROOT_PATH / "configs/splitter.yml",
    ]
)

# Cell
config, FIG_SIZE = use_berlin_segmentation_test(config)

# Cell
pipeline = Pipeline.create_from_config(
    config,
    get_toolbox_lookup(),
)
pipeline.run()

# Cell
train_sample_idx, val_sample_idx = next(iter(pipeline.get_node_output("DataSplitCreator")().split()))
module = pipeline.get_node_output("ModuleCreator")(
    train_samples=pipeline.get_node_output("TrainSampleDataCreator")[train_sample_idx],
    val_samples=pipeline.get_node_output("TrainSampleDataCreator")[val_sample_idx],
    test_samples=pipeline.get_node_output("TestSampleDataCreator"),
)
trainer = pipeline.get_node_output("TrainerCreator")(checkpoint_callback=pipeline.get_node_output("PyTorchLightningModelCheckpoint"))
recorder = pipeline.get_node_output("ImageSegmentationResultRecorder")

# Cell
before_train_module_weights = copy_and_flatten_model_weights(module.model)
trainer.fit(module)
after_train_module_weights = copy_and_flatten_model_weights(module.model)
trainer.test()

assert not all(
    [
        arrays_are_same(before_parameters, after_parameters)
        for before_parameters, after_parameters in zip(before_train_module_weights, after_train_module_weights)
    ]
)
assert all_methods_in_callback_handler_are_called(pipeline.get_node_output("CallbackHandler"))

# Cell
checkpoint_callback = pipeline.get_node_output("PyTorchLightningModelCheckpoint")
checkpoint_path = str(Path(checkpoint_callback.model_save_path) / checkpoint_callback.current_model_save_name)

# Cell
inference_pipeline = Pipeline.create_from_config(
    config,
    get_toolbox_lookup(),
)
inference_pipeline.run()

inference_module = inference_pipeline.get_node_output("ModuleCreator")(
    train_samples=inference_pipeline.get_node_output("TrainSampleDataCreator")[train_sample_idx],
    val_samples=inference_pipeline.get_node_output("TrainSampleDataCreator")[val_sample_idx],
    test_samples=inference_pipeline.get_node_output("TestSampleDataCreator"),
)
inference_trainer = inference_pipeline.get_node_output("TrainerCreator")(
    checkpoint_callback=inference_pipeline.get_node_output("PyTorchLightningModelCheckpoint")
)

before_load_inference_module_weights = copy_and_flatten_model_weights(inference_module.model)

assert id(trainer) != id(inference_trainer)
assert id(module.model) != id(inference_module.model)
assert id(before_train_module_weights) != id(before_load_inference_module_weights)
assert not all(
    [
        arrays_are_same(module_parameters, checkpoint_parameters)
        for module_parameters, checkpoint_parameters in zip(before_train_module_weights, before_load_inference_module_weights)
    ]
)
pl_checkpoint = pl_load(checkpoint_path, map_location=lambda storage, loc: storage)
inference_module.load_state_dict(pl_checkpoint["state_dict"])

after_load_inference_module_weights = copy_and_flatten_model_weights(inference_module.model)

assert id(before_load_inference_module_weights) != id(after_load_inference_module_weights)
assert not all(
    [
        arrays_are_same(before_parameters, after_parameters)
        for before_parameters, after_parameters in zip(before_load_inference_module_weights, after_load_inference_module_weights)
    ]
)
assert all(
    [
        arrays_are_same(after_train_parameters, after_load_parameters)
        for after_train_parameters, after_load_parameters in zip(after_train_module_weights, after_load_inference_module_weights)
    ]
)

# Cell
test_samples = pipeline.get_node_output("TestSampleDataCreator")
test_dataset = pipeline.get_node_output("TestDatasetCreator")(test_samples)
test_dataloader = pipeline.get_node_output("TestDataLoaderCreator")(test_dataset)
trainer_predictions = trainer.test(module, test_dataloaders=[test_dataloader])
inference_trainer_predictions = inference_trainer.test(inference_module, test_dataloaders=[test_dataloader])
assert str(trainer_predictions) == str(inference_trainer_predictions)

# Cell
mlflow_save_path = pipeline.get_node_output("TimeStampedSavePath") / "mlflow"
save_mlflow_pyfunc_model(
    mlflow_save_path,
    pipeline.get_node_output("ServingModel"),
    artifacts={
        "config_path": str(checkpoint_callback.best_config_path),
        "model_save_path": str(checkpoint_callback.best_model_path),
    },
)

test_samples_json = {
    "columns": ["images"],
    "index": [i for i in range(len(test_samples))],
    "data": [[create_segmentation_sample(**s).image.data.tolist()] for s in test_samples],
}

images_df = pd.read_json(json.dumps(test_samples_json), orient="split")
mlflow_model = load_mlflow_pyfunc_model(str(mlflow_save_path))
mlflow_predictions = mlflow_model.predict(images_df)

test_samples_with_paths_json = {
    "columns": ["image_paths"],
    "index": [i for i in range(len(test_samples))],
    "data": [[str(create_segmentation_sample(**s).image.path)] for s in test_samples],
}
images_df = pd.read_json(json.dumps(test_samples_with_paths_json), orient="split")
mlflow_model = load_mlflow_pyfunc_model(str(mlflow_save_path))
mlflow_predictions = mlflow_model.predict(images_df)

# Cell
import tempfile
import time

import requests

from roheboam.engine.integrations.docker import containerise_model, containerise_model_debug, run_docker_container
from roheboam.engine.utils.convenience import get_open_port

# Cell
source_path = str(ROOT_PATH).split("/examples")[0]
model_image = f"berlin-image-segmentation:{pipeline.get_node_output('TimeStampedSavePath').name}"
containerise_model_debug(
    source_path=source_path,
    model_path=mlflow_save_path,
    model_image=model_image,
)

# Cell
port = get_open_port()
container = run_docker_container(model_image, port=port, gpus=str(config["Variables"]["gpus"]))

# Cell
try:
    for _ in range(5):
        try:
            response = requests.post(
                f"http://0.0.0.0:{port}/invocations",
                data=json.dumps(test_samples_json),
                headers={"Content-Type": "application/json"},
            )
            assert response.status_code == 200
            break
        except Exception:
            print("Connection Error")
            time.sleep(5)
finally:
    container.stop()
