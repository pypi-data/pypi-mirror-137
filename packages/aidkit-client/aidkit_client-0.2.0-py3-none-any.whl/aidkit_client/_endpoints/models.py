# generated by datamodel-codegen:
#   filename:  <stdin>

from __future__ import annotations

from enum import Enum
from typing import Any, Dict, List, Optional, Union

from pydantic import BaseModel, Field
from typing_extensions import Literal


class MLModelVersionResponse(BaseModel):
    """
    MLModel version response model.
    """

    id: int = Field(..., title="Id")
    name: str = Field(..., title="Name")
    pipeline_run_ids: List[int] = Field(..., title="Pipeline Run Ids")


class ListMLModelVersionResponse(BaseModel):
    """
    List MLModel version response model.
    """

    ml_model_versions: List[MLModelVersionResponse] = Field(..., title="Ml Model Versions")


class FrameworkType(Enum):
    """
    Identification of the type of deep learning framework.

    Required for parsing model binaries with the correct libraries.
    """

    TENSORFLOW = "TENSORFLOW"
    PYTORCH = "PYTORCH"


class BatchDim(Enum):
    """
    Location of batch dimension, if it exists.
    """

    First = "First"
    Last = "Last"
    No_Batch = "No Batch"


class DimensionModel(BaseModel):
    """
    Dimension has an axis and length field.
    """

    axis: int = Field(..., title="Axis")
    length: Union[int, Literal["*"]] = Field(..., title="Length")


class GrayScaleChannelDimensionModel(BaseModel):
    """
    Gray scale channel dimension must be of length 1.
    """

    axis: int = Field(..., title="Axis")
    length: Literal[1] = Field(1, title="Length")


class UnspecifiedLengthDimensionModel(BaseModel):
    """
    Output dimension can be of any length.
    """

    axis: int = Field(..., title="Axis")
    length: Literal["*"] = Field("*", title="Length")


class GrayScaleImageInputDimensionsModel(BaseModel):
    """
    Gray Scale Image input has optional batch dimension.
    """

    height: DimensionModel = Field(
        ..., description="Height axis index and length", title="Height axis"
    )
    width: DimensionModel = Field(
        ..., description="Width axis index and length", title="Width axis"
    )
    channel: GrayScaleChannelDimensionModel = Field(
        ..., description="Channel axis index", title="Channel axis"
    )
    batch: Optional[UnspecifiedLengthDimensionModel] = Field(
        None, description="Batch axis and length", title="Batch axis"
    )


class InputRangeTypes(Enum):
    """
    Range of pixel values.
    """

    MinusOneOne = "MinusOneOne"
    ZeroOne = "ZeroOne"
    Standardize = "Standardize"


class NormalizerSpecs(BaseModel):
    """
    Specs for normalization step.
    """

    input_range: InputRangeTypes = Field("ZeroOne", title="Expected Input Range")
    data_mean: Optional[float] = Field(None, title="Dataset Mean (only for Standardize)")
    data_std: Optional[float] = Field(
        None, ge=0.0, title="Dataset Standard Deviation (only for Standardize)"
    )


class GrayScaleImageInputSpecs(BaseModel):
    """
    A grayscale image has 1 channel.
    """

    name: Literal["GrayScaleImage"] = Field("GrayScaleImage", title="Image (Grayscale)")
    batch_dim: BatchDim = Field("No Batch", title="Batch Axis Location")
    dimensions: GrayScaleImageInputDimensionsModel
    normalizer: NormalizerSpecs = Field(
        {"input_range": "ZeroOne", "data_mean": None, "data_std": None}, title="Normalizer"
    )


class ColorChannelDimensionModel(BaseModel):
    """
    Color channel dimension must be of length 3.
    """

    axis: int = Field(..., title="Axis")
    length: Literal[3] = Field(3, title="Length")


class ColorImageInputDimensionsModel(BaseModel):
    """
    Color Image input has optional batch dimension.
    """

    height: DimensionModel = Field(
        ..., description="Height axis index and length", title="Height axis"
    )
    width: DimensionModel = Field(
        ..., description="Width axis index and length", title="Width axis"
    )
    channel: ColorChannelDimensionModel = Field(
        ..., description="Channel axis index", title="Channel axis"
    )
    batch: Optional[UnspecifiedLengthDimensionModel] = Field(
        None, description="Batch axis and length", title="Batch axis"
    )


class ColorImageInputSpecs(BaseModel):
    """
    A color image has 3 channels.
    """

    name: Literal["ColorImage"] = Field("ColorImage", title="Image (Color)")
    batch_dim: BatchDim = Field("No Batch", title="Batch Axis Location")
    dimensions: ColorImageInputDimensionsModel
    normalizer: NormalizerSpecs = Field(
        {"input_range": "ZeroOne", "data_mean": None, "data_std": None}, title="Normalizer"
    )


class ConintForAutogenerated(BaseModel):
    __root__: int = Field(
        ...,
        description=(
            "Specify the total number of classes. The class names are auto-generated, e.g.,"
            " class_01, class_02, ..., class_10 for a total of 10 classes."
        ),
        gt=0.0,
        title="Autogenerated",
    )


class DictOutputFormat(BaseModel):
    """
    Model outputs a dictionary of tensors.
    """

    name: Literal["Dict"] = Field("Dict", title="Dictionary of Tensors")
    output_target: str = Field(..., title="Output Target")


class SingleOutputFormat(BaseModel):
    """
    Model outputs a single tensor.
    """

    name: Literal["Single"] = Field("Single", title="Single Tensor")


class SegmentationScoreDimensionsModel(BaseModel):
    """
    Segmentation Output has width, height, and class dimensions.
    """

    width: UnspecifiedLengthDimensionModel = Field(..., title="Width axis")
    height: UnspecifiedLengthDimensionModel = Field(..., title="Height axis")
    class_: UnspecifiedLengthDimensionModel = Field(..., title="Class axis")
    batch: Optional[UnspecifiedLengthDimensionModel] = Field(None, title="Batch axis")


class SegmentationModelOutputSpecs(BaseModel):
    """
    Model returns a segmentation map, i.e., a tensor of logit scores for all
    classes for each pixel.
    """

    class_names: Optional[Union[List[str], ConintForAutogenerated]] = Field(
        None, description="List of class names or number of classes", title="Class Names"
    )
    output_format: Union[DictOutputFormat, SingleOutputFormat] = Field(..., title="Output Format")
    dimensions: SegmentationScoreDimensionsModel
    name: str = Field("SegmentationOutput", title="Segmentation")


class ClassificationScoreDimensionsModel(BaseModel):
    """
    Classification Output has class dimension.
    """

    class_: Optional[UnspecifiedLengthDimensionModel] = Field(None, title="Class axis")
    batch: Optional[UnspecifiedLengthDimensionModel] = Field(None, title="Batch axis")


class ClassificationModelOutputSpecs(BaseModel):
    """
    Model returns a classification, i.e., a tensor of logit scores for all
    classes.
    """

    class_names: Optional[Union[List[str], ConintForAutogenerated]] = Field(
        None, description="List of class names or number of classes", title="Class Names"
    )
    output_format: Union[DictOutputFormat, SingleOutputFormat] = Field(..., title="Output Format")
    dimensions: Optional[ClassificationScoreDimensionsModel] = Field(
        None, title="Classification Score Dimensions"
    )
    name: Literal["ClassificationOutput"] = Field("ClassificationOutput", title="Classification")


class ImageModelContextSpecs(BaseModel):
    """
    Model for image input types.
    """

    name: Literal["ImageModelContext"] = Field("ImageModelContext", title="Computer Vision")
    input_specification: Union[GrayScaleImageInputSpecs, ColorImageInputSpecs] = Field(
        ..., title="Data Type"
    )
    output_specification: ClassificationModelOutputSpecs = Field(..., title="Task")


class NgramInputDimensionsModel(BaseModel):
    """
    Ngram input has optional batch dimension, index and feature dimensions are
    hardcoded.
    """

    batch: Optional[UnspecifiedLengthDimensionModel] = Field(
        None, description="Batch axis and length", title="Batch axis"
    )


class NoPreTokenizerSpecs(BaseModel):
    """
    Do not apply pre-tokenization.
    """

    name: Literal["NoPreTokenizer"] = Field("NoPreTokenizer", title="No Pre-Tokenizer")


class SplitPreTokenizerSpecs(BaseModel):
    """
    Split text input before tokenization.
    """

    name: Literal["SplitPreTokenizer"] = Field("SplitPreTokenizer", title="Split")
    convert_to_lower_case: bool = Field(
        True,
        description=(
            "Whether to convert the text input to lower case. If True, 'This is A sentence' ->"
            " 'this is a sentence'. If False, 'This is A Sentence' -> 'This is A sentence'. "
        ),
        title="Convert to Lower Case",
    )
    whitespace: bool = Field(
        True,
        description=(
            "Whether to separate the input text into words. If True, 'this is a sentence' ->"
            " 'this', 'is', 'a', 'sentence'. If False, 'this is a sentence' -> 'this is a"
            " sentence'. "
        ),
        title="Split by Whitespace",
    )
    keep_punctuation: bool = Field(
        True,
        description=(
            "Whether to keep punctuation (.,;:!?()) as separate tokens. If True, 'hello! this is a"
            " sentence.' -> 'hello', '!', 'this', 'is', 'a', 'sentence', '.'If False, 'hello! this"
            " is a sentence.' -> 'hello', 'this', 'is', 'a', 'sentence'"
        ),
        title="Keep Punctuation",
    )


class ByteLevelPreTokenizerSpecs(BaseModel):
    """
    Encoding that maps each byte value to a unique symbol.
    """

    name: Literal["ByteLevelPreTokenizer"] = Field("ByteLevelPreTokenizer", title="Byte Level")


class NoTokenizerSpecs(BaseModel):
    """
    Do not apply tokenization.
    """

    name: Literal["NoTokenizer"] = Field("NoTokenizer", title="No Tokenizer")


class WordLevelTokenizerSpecs(BaseModel):
    """
    A word-level tokenizer maps each token to an ID according to a vocabulary.
    """

    name: Literal["WordLevelTokenizer"] = Field("WordLevelTokenizer", title="Word Level")
    vocab: str = Field(
        ...,
        description=(
            "The expected format is a JSON representation of a dictionary where the keys are the"
            " symbols in the vocabulary (strings) and the values are the corresponding IDs"
            ' (integers), e.g.: {"hello": 1, "world": 2, "[UNK]": 3}'
        ),
        title="Vocabulary",
    )
    unk_token: str = Field(
        "[UNK]",
        description="Symbol to represent tokens that are not in the vocabulary.",
        title="Unknown Token",
    )


class BPETokenizerSpecs(BaseModel):
    """
    Byte-Pair Encoding (BPE) creates a 'merge list' and an according vocabulary
    by iteratively creating entries from merging the most frequent symbol
    pairs.

    During tokenization, tokens are first merged according to the 'merge
    list' and then mapped to IDs using the vocabulary.
    """

    name: Literal["BPETokenizer"] = Field("BPETokenizer", title="BPE Tokenizer")
    vocab: str = Field(
        ...,
        description=(
            "The expected format is a JSON representation of a dictionary where the keys are the"
            " symbols in the vocabulary (strings) and the values are the corresponding IDs"
            ' (integers), e.g.: {"hello": 1, "world": 2, "[UNK]": 3}'
        ),
        title="Vocabulary",
    )
    merges: str = Field(
        ...,
        description=(
            "Symbol pairs to be merged during Byte-Pair Encoding. The expected format is a text"
            " where each line contains one pair of symbols, i.e.:\na b\nc d\ne f\n"
        ),
        title="Merges",
    )
    unk_token: str = Field(
        "[UNK]",
        description="Symbol to represent tokens that are not in the vocabulary.",
        title="Unknown Token",
    )


class NgramInputSpecs(BaseModel):
    """
    A string input.
    """

    name: Literal["Text"] = Field("Text", title="Text")
    batch_dim: BatchDim = Field("No Batch", title="Batch Axis Location")
    dimensions: Optional[NgramInputDimensionsModel] = None
    pre_tokenizer: Union[
        NoPreTokenizerSpecs, SplitPreTokenizerSpecs, ByteLevelPreTokenizerSpecs
    ] = Field(..., title="Pre-Tokenizer")
    tokenizer: Union[NoTokenizerSpecs, WordLevelTokenizerSpecs, BPETokenizerSpecs] = Field(
        ..., title="Tokenizer"
    )


class TextModelContextSpecs(BaseModel):
    """
    Model for text input types.
    """

    name: Literal["TextModelContext"] = Field(
        "TextModelContext", title="Natural Language Processing"
    )
    input_specification: NgramInputSpecs = Field(..., title="Data Type")
    output_specification: ClassificationModelOutputSpecs = Field(..., title="Task")


class MLModelResponse(BaseModel):
    """
    MLModel response model.
    """

    id: int = Field(..., title="Id")
    name: str = Field(..., title="Name")
    versions: List[MLModelVersionResponse] = Field(..., title="Versions")
    framework: FrameworkType
    context: Union[ImageModelContextSpecs, TextModelContextSpecs] = Field(..., title="Context")


class ListMLModelResponse(BaseModel):
    """
    List MLModel response model.
    """

    ml_models: List[MLModelResponse] = Field(..., title="Ml Models")


class TargetClassInput(BaseModel):
    """
    Union of str/int used as an input.
    """

    name: Literal["TargetClassInput"] = Field(
        "TargetClassInput",
        description=(
            "Specifies the target class used by an algorithm either by `index` (an integer value"
            " starting with 0) or by taking the argmax of the model prediction."
        ),
        title="Target Class",
    )
    value: Union[int, Literal["argmax"]] = Field(..., title="Value")


class IdentifierInput(BaseModel):
    """
    An entity identifier.
    """

    name: Literal["IdentifierInput"] = Field(
        "IdentifierInput",
        description='Identifier (ID) for a resource such as "Dataset" and "Pipeline".',
        title="Resource ID",
    )
    value: int = Field(..., title="Value")


class UserProvidedContext(BaseModel):
    pipeline_node_id: int = Field(..., title="Pipeline Node Id")
    context_name: str = Field(..., title="Context Name")
    value: Union[TargetClassInput, IdentifierInput] = Field(..., title="Value")


class CreatePipelineRunRequest(BaseModel):
    pipeline_id: int = Field(..., title="Pipeline Id")
    context: List[UserProvidedContext] = Field(..., title="Context")


class PipelineRunState(Enum):
    """
    Life cycle of a pipeline run.
    """

    PENDING = "PENDING"
    STOPPED = "STOPPED"
    RUNNING = "RUNNING"
    SUCCESS = "SUCCESS"
    FAILED = "FAILED"


class PipelineRunNodeResponse(BaseModel):
    id: int = Field(..., title="Id")
    state: PipelineRunState


class NamedEntity(BaseModel):
    id: int = Field(..., title="Id")
    name: str = Field(..., title="Name")


class PipelineRunResponse(BaseModel):
    id: int = Field(..., title="Id")
    state: PipelineRunState
    nodes: List[PipelineRunNodeResponse] = Field(..., title="Nodes")
    ml_model: Optional[NamedEntity] = None
    ml_model_version: Optional[NamedEntity] = None
    dataset: Optional[NamedEntity] = None
    subset: Optional[NamedEntity] = None
    pipeline: Optional[NamedEntity] = None


class PipelineRunListResponse(BaseModel):
    pipeline_runs: List[PipelineRunResponse] = Field(..., title="Pipeline Runs")


class RequiredContextDescription(BaseModel):
    pipeline_node_id: int = Field(..., title="Pipeline Node Id")
    context_name: str = Field(..., title="Context Name")
    context_type: Dict[str, Any] = Field(..., title="Context Type")


class RequiredContextResponse(BaseModel):
    items: List[RequiredContextDescription] = Field(..., title="Items")


class ReportMethod(BaseModel):
    method_name: str = Field(..., title="Method Name")
    param_string: str = Field(..., title="Param String")
    pipeline_node_id: int = Field(..., title="Pipeline Node Id")


class ReportObservation(BaseModel):
    id: int = Field(..., title="Id")
    name: str = Field(..., title="Name")
    thumbnail_url: str = Field(..., title="Thumbnail Url")


class ReportEntry(BaseModel):
    method_name: str = Field(..., title="Method Name")
    param_string: str = Field(..., title="Param String")
    plot_url: str = Field(..., title="Plot Url")
    observation: ReportObservation


class ReportMethodResponse(BaseModel):
    report_target: ReportMethod
    artifacts: List[ReportEntry] = Field(..., title="Artifacts")


class ReportObservationResponse(BaseModel):
    report_target: ReportObservation
    artifacts: List[ReportEntry] = Field(..., title="Artifacts")


class ReportAverageRow(BaseModel):
    method: ReportMethod
    metric: ReportMethod
    metric_value: float = Field(..., title="Metric Value")


class TabularReport(BaseModel):
    rows: List[ReportAverageRow] = Field(..., title="Rows")
    observations: List[ReportObservation] = Field(..., title="Observations")
    methods: List[ReportMethod] = Field(..., title="Methods")


class SubsetResponse(BaseModel):
    id: int = Field(..., title="Id")
    name: str = Field(..., title="Name")
    observation_ids: List[int] = Field(..., title="Observation Ids")


class SubsetCreateRequest(BaseModel):
    name: str = Field(..., title="Name")
    dataset_name: str = Field(..., title="Dataset Name")
    observation_ids: List[int] = Field(..., title="Observation Ids")


class SubsetUpdateRequest(BaseModel):
    name: str = Field(..., title="Name")
    observation_ids: List[int] = Field(..., title="Observation Ids")


class ObservationResponse(BaseModel):
    id: int = Field(..., title="Id")
    type: str = Field(..., title="Type")
    file_name: str = Field(..., title="File Name")
    file_url: Optional[str] = Field(None, title="File Url")


class DatasetResponse(BaseModel):
    id: int = Field(..., title="Id")
    name: str = Field(..., title="Name")
    type: str = Field(..., title="Type")
    observation_ids: List[int] = Field(..., title="Observation Ids")
    subsets: List[SubsetResponse] = Field(..., title="Subsets")


class ObservationType(Enum):
    """
    Identification of the type of an observation.

    Required for parsing an observation into a core-object.
    """

    NGRAM = "NGRAM"
    COLOR_IMAGE = "COLOR_IMAGE"
    GREY_SCALE_IMAGE = "GREY_SCALE_IMAGE"


class DatasetUploadRequest(BaseModel):
    name: str = Field(..., title="Name")
    type: ObservationType


class _ModelCompilation(BaseModel):
    ml_model_version_response: MLModelVersionResponse
    list_ml_model_version_response: ListMLModelVersionResponse
    ml_model_response: MLModelResponse
    list_ml_model_response: ListMLModelResponse
    create_pipeline_run_request: CreatePipelineRunRequest
    pipeline_run_response: PipelineRunResponse
    pipeline_run_list_response: PipelineRunListResponse
    required_context_response: RequiredContextResponse
    report_method_response: ReportMethodResponse
    report_observation_response: ReportObservationResponse
    tabular_report: TabularReport
    subset_response: SubsetResponse
    subset_create_request: SubsetCreateRequest
    subset_update_request: SubsetUpdateRequest
    observation_response: ObservationResponse
    dataset_response: DatasetResponse
    dataset_request: DatasetUploadRequest
