# coding=utf-8
# --------------------------------------------------------------------------
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is
# regenerated.
# --------------------------------------------------------------------------

from msrest.serialization import Model


class DatabricksConfiguration(Model):
    """DatabricksConfiguration.

    :param workers:
    :type workers: int
    :param minimum_worker_count:
    :type minimum_worker_count: int
    :param max_mum_worker_count:
    :type max_mum_worker_count: int
    :param spark_version:
    :type spark_version: str
    :param node_type_id:
    :type node_type_id: str
    :param spark_conf:
    :type spark_conf: dict[str, str]
    :param spark_env_vars:
    :type spark_env_vars: dict[str, str]
    :param cluster_log_conf_dbfs_path:
    :type cluster_log_conf_dbfs_path: str
    :param dbfs_init_scripts:
    :type dbfs_init_scripts: list[~designer.models.InitScriptInfoDto]
    :param instance_pool_id:
    :type instance_pool_id: str
    :param timeout_seconds:
    :type timeout_seconds: int
    :param notebook_task:
    :type notebook_task: ~designer.models.NoteBookTaskDto
    :param spark_python_task:
    :type spark_python_task: ~designer.models.SparkPythonTaskDto
    :param spark_jar_task:
    :type spark_jar_task: ~designer.models.SparkJarTaskDto
    :param spark_submit_task:
    :type spark_submit_task: ~designer.models.SparkSubmitTaskDto
    :param jar_libraries:
    :type jar_libraries: list[str]
    :param egg_libraries:
    :type egg_libraries: list[str]
    :param whl_libraries:
    :type whl_libraries: list[str]
    :param pypi_libraries:
    :type pypi_libraries: list[~designer.models.PythonPyPiOrRCranLibraryDto]
    :param r_cran_libraries:
    :type r_cran_libraries: list[~designer.models.PythonPyPiOrRCranLibraryDto]
    :param maven_libraries:
    :type maven_libraries: list[~designer.models.MavenLibraryDto]
    :param libraries:
    :type libraries: list[object]
    :param linked_adb_workspace_metadata:
    :type linked_adb_workspace_metadata:
     ~designer.models.LinkedADBWorkspaceMetadata
    :param databrick_resource_id:
    :type databrick_resource_id: str
    :param auto_scale:
    :type auto_scale: bool
    """

    _attribute_map = {
        'workers': {'key': 'workers', 'type': 'int'},
        'minimum_worker_count': {'key': 'minimumWorkerCount', 'type': 'int'},
        'max_mum_worker_count': {'key': 'maxMumWorkerCount', 'type': 'int'},
        'spark_version': {'key': 'sparkVersion', 'type': 'str'},
        'node_type_id': {'key': 'nodeTypeId', 'type': 'str'},
        'spark_conf': {'key': 'sparkConf', 'type': '{str}'},
        'spark_env_vars': {'key': 'sparkEnvVars', 'type': '{str}'},
        'cluster_log_conf_dbfs_path': {'key': 'clusterLogConfDbfsPath', 'type': 'str'},
        'dbfs_init_scripts': {'key': 'dbfsInitScripts', 'type': '[InitScriptInfoDto]'},
        'instance_pool_id': {'key': 'instancePoolId', 'type': 'str'},
        'timeout_seconds': {'key': 'timeoutSeconds', 'type': 'int'},
        'notebook_task': {'key': 'notebookTask', 'type': 'NoteBookTaskDto'},
        'spark_python_task': {'key': 'sparkPythonTask', 'type': 'SparkPythonTaskDto'},
        'spark_jar_task': {'key': 'sparkJarTask', 'type': 'SparkJarTaskDto'},
        'spark_submit_task': {'key': 'sparkSubmitTask', 'type': 'SparkSubmitTaskDto'},
        'jar_libraries': {'key': 'jarLibraries', 'type': '[str]'},
        'egg_libraries': {'key': 'eggLibraries', 'type': '[str]'},
        'whl_libraries': {'key': 'whlLibraries', 'type': '[str]'},
        'pypi_libraries': {'key': 'pypiLibraries', 'type': '[PythonPyPiOrRCranLibraryDto]'},
        'r_cran_libraries': {'key': 'rCranLibraries', 'type': '[PythonPyPiOrRCranLibraryDto]'},
        'maven_libraries': {'key': 'mavenLibraries', 'type': '[MavenLibraryDto]'},
        'libraries': {'key': 'libraries', 'type': '[object]'},
        'linked_adb_workspace_metadata': {'key': 'linkedADBWorkspaceMetadata', 'type': 'LinkedADBWorkspaceMetadata'},
        'databrick_resource_id': {'key': 'databrickResourceId', 'type': 'str'},
        'auto_scale': {'key': 'autoScale', 'type': 'bool'},
    }

    def __init__(self, **kwargs):
        super(DatabricksConfiguration, self).__init__(**kwargs)
        self.workers = kwargs.get('workers', None)
        self.minimum_worker_count = kwargs.get('minimum_worker_count', None)
        self.max_mum_worker_count = kwargs.get('max_mum_worker_count', None)
        self.spark_version = kwargs.get('spark_version', None)
        self.node_type_id = kwargs.get('node_type_id', None)
        self.spark_conf = kwargs.get('spark_conf', None)
        self.spark_env_vars = kwargs.get('spark_env_vars', None)
        self.cluster_log_conf_dbfs_path = kwargs.get('cluster_log_conf_dbfs_path', None)
        self.dbfs_init_scripts = kwargs.get('dbfs_init_scripts', None)
        self.instance_pool_id = kwargs.get('instance_pool_id', None)
        self.timeout_seconds = kwargs.get('timeout_seconds', None)
        self.notebook_task = kwargs.get('notebook_task', None)
        self.spark_python_task = kwargs.get('spark_python_task', None)
        self.spark_jar_task = kwargs.get('spark_jar_task', None)
        self.spark_submit_task = kwargs.get('spark_submit_task', None)
        self.jar_libraries = kwargs.get('jar_libraries', None)
        self.egg_libraries = kwargs.get('egg_libraries', None)
        self.whl_libraries = kwargs.get('whl_libraries', None)
        self.pypi_libraries = kwargs.get('pypi_libraries', None)
        self.r_cran_libraries = kwargs.get('r_cran_libraries', None)
        self.maven_libraries = kwargs.get('maven_libraries', None)
        self.libraries = kwargs.get('libraries', None)
        self.linked_adb_workspace_metadata = kwargs.get('linked_adb_workspace_metadata', None)
        self.databrick_resource_id = kwargs.get('databrick_resource_id', None)
        self.auto_scale = kwargs.get('auto_scale', None)
