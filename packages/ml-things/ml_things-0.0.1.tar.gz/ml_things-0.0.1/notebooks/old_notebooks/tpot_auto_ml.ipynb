{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tpot_auto_ml.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gmihaila/machine_learning_toolbox/blob/master/tpot_auto_ml.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "vQGgkN-3Xm_G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## [T Pot](https://towardsdatascience.com/tpot-automated-machine-learning-in-python-4c063b3e5de9)\n",
        "\n",
        "More details [here](http://epistasislab.github.io/tpot/)\n",
        "\n",
        "Optionally, you can install **XGBoost** if you would like TPOT to use the eXtreme Gradient Boosting models\n",
        "\n",
        "Tutorial:\n",
        "\n",
        "https://towardsdatascience.com/automated-machine-learning-on-the-cloud-in-python-47cf568859f\n",
        "https://colab.research.google.com/drive/1CIVn-GoOyY3H2_Bv8z09mkNRokQ9jlJ-#scrollTo=g268joSvPGMl"
      ]
    },
    {
      "metadata": {
        "id": "D9MVOGOzXmZo",
        "colab_type": "code",
        "outputId": "0dd87a42-1636-4787-e3f1-caac86a6f93c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# Install pydot\n",
        "print(\"Installing graphiz and pydot\")\n",
        "!apt-get -qq install -y graphviz && pip install -q pydot\n",
        "clear_output()\n",
        "\n",
        "print(\"Installing tpot\")\n",
        "!pip install xgboost\n",
        "!pip install tpot\n",
        "# !pip install --upgrade --no-deps --force-reinstall git+https://github.com/weixuanfu/tpot.git@scoring_api_bug\n",
        "clear_output()\n",
        "\n",
        "\n",
        "print(\"Downloading pima-indians-diabetes\")\n",
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\n",
        "clear_output()\n",
        "\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pima-indians-diabetes.data.csv\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "asjTy_-fXj8d",
        "colab_type": "code",
        "outputId": "00138d87-8599-4f74-8221-fe031f4579cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tpot import TPOTClassifier\n",
        "\n",
        "#scikit-learn package (https://pypi.org/project/scikit-learn)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split #TAKES NUMPY OR DATA FRAME!!\n",
        "from sklearn.metrics.scorer import make_scorer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Split train and test set.\n",
        "RANDOM_STATE = 123\n",
        "\n",
        "# Parse data\n",
        "path_file = 'pima-indians-diabetes.data.csv'\n",
        "\n",
        "df = pd.read_csv(path_file, header=None)\n",
        "\n",
        "x_df = df.drop(df.columns[8],axis=1)\n",
        "y_df = df[df.columns[8]]\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1   2   3    4     5      6   7  8\n",
              "0  6  148  72  35    0  33.6  0.627  50  1\n",
              "1  1   85  66  29    0  26.6  0.351  31  0\n",
              "2  8  183  64   0    0  23.3  0.672  32  1\n",
              "3  1   89  66  23   94  28.1  0.167  21  0\n",
              "4  0  137  40  35  168  43.1  2.288  33  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "vUzzs5y-Zc_r",
        "colab_type": "code",
        "outputId": "6991236b-5d1b-4fef-a688-e80569bca1c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "X, X_test, y, y_test = train_test_split(x_df, y_df, train_size=0.85, random_state=42)\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.85, random_state=RANDOM_STATE)\n",
        "\n",
        "\n",
        "print(\"Train: \", X_train.shape[0])\n",
        "print(\"Validation: \",X_validation.shape[0])\n",
        "print(\"Test: \",X_test.shape[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Train: ', 554)\n",
            "('Validation: ', 98)\n",
            "('Test: ', 116)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tKGiZ_0kr1uF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "how to config:\n",
        "https://epistasislab.github.io/tpot/api/\n",
        "\n",
        "    class tpot.TPOTClassifier(\n",
        "                                generations=100, population_size=100,\n",
        "                                offspring_size=None, mutation_rate=0.9,\n",
        "                                crossover_rate=0.1,\n",
        "                                scoring='accuracy', cv=5,\n",
        "                                subsample=1.0, n_jobs=1,\n",
        "                                max_time_mins=None, max_eval_time_mins=5,\n",
        "                                random_state=None, config_dict=None,\n",
        "                                warm_start=False,\n",
        "                                memory=None,\n",
        "                                use_dask=False,\n",
        "                                periodic_checkpoint_folder=None,\n",
        "                                early_stop=None,\n",
        "                                verbosity=0,\n",
        "                                disable_update_check=False\n",
        "                              )"
      ]
    },
    {
      "metadata": {
        "id": "gUd8bHePZiT7",
        "colab_type": "code",
        "outputId": "810c7dd2-43bf-4e3d-8b6f-3d0bd67a8cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1855
        }
      },
      "cell_type": "code",
      "source": [
        "tpot = None\n",
        "del tpot\n",
        "\n",
        "tpot = TPOTClassifier(\n",
        "                      verbosity=3, \n",
        "                      scoring=\"accuracy\", \n",
        "                      random_state=23, \n",
        "                      periodic_checkpoint_folder=\"periodic_checkpoint_folder\", \n",
        "                      n_jobs=-1, \n",
        "                      generations=10, \n",
        "                      population_size=50\n",
        ")\n",
        "\n",
        "tpot.fit(X, y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30 operators have been imported by TPOT.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:   9%|▉         | 50/550 [00:21<03:24,  2.44pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:   9%|▉         | 50/550 [00:23<03:24,  2.44pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:   9%|▉         | 50/550 [00:25<03:24,  2.44pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:   9%|▉         | 50/550 [00:25<03:24,  2.44pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:   9%|▉         | 50/550 [00:26<03:24,  2.44pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:   9%|▉         | 51/550 [00:27<16:26,  1.98s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 101/550 [00:56<05:05,  1.47pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 1 - Current Pareto front scores:\n",
            "-1\t0.779172823153\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.35000000000000003, RandomForestClassifier__min_samples_leaf=7, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=100)\n",
            "\n",
            "Created new folder to save periodic pipeline: periodic_checkpoint_folder\n",
            "Saving best periodic pipeline to periodic_checkpoint_folder/pipeline_2018.10.24_16-28-21.py\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 101/550 [00:57<04:10,  1.79pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 101/550 [00:58<04:10,  1.79pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 101/550 [00:59<04:10,  1.79pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 101/550 [01:00<04:10,  1.79pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 101/550 [01:02<04:10,  1.79pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 151/550 [01:37<04:20,  1.53pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 2 - Current Pareto front scores:\n",
            "-1\t0.779172823153\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.35000000000000003, RandomForestClassifier__min_samples_leaf=7, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=100)\n",
            "\n",
            "Periodic pipeline was not saved, probably saved before...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 151/550 [01:38<04:05,  1.63pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 151/550 [01:39<04:05,  1.63pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 151/550 [01:39<04:05,  1.63pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  28%|██▊       | 152/550 [01:45<18:09,  2.74s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  37%|███▋      | 201/550 [02:33<05:46,  1.01pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 3 - Current Pareto front scores:\n",
            "-1\t0.786889347117\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.35000000000000003, RandomForestClassifier__min_samples_leaf=5, RandomForestClassifier__min_samples_split=17, RandomForestClassifier__n_estimators=100)\n",
            "\n",
            "Saving best periodic pipeline to periodic_checkpoint_folder/pipeline_2018.10.24_16-29-58.py\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  37%|███▋      | 201/550 [02:35<05:05,  1.14pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  37%|███▋      | 201/550 [02:36<05:05,  1.14pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  37%|███▋      | 201/550 [02:46<05:05,  1.14pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  37%|███▋      | 204/550 [02:47<14:19,  2.48s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  46%|████▌     | 251/550 [03:49<06:07,  1.23s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 4 - Current Pareto front scores:\n",
            "-1\t0.786889347117\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.35000000000000003, RandomForestClassifier__min_samples_leaf=5, RandomForestClassifier__min_samples_split=17, RandomForestClassifier__n_estimators=100)\n",
            "\n",
            "Periodic pipeline was not saved, probably saved before...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  46%|████▌     | 251/550 [03:50<05:45,  1.16s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  46%|████▌     | 251/550 [03:51<05:45,  1.16s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  46%|████▌     | 251/550 [03:55<05:45,  1.16s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  46%|████▌     | 251/550 [03:58<05:45,  1.16s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  55%|█████▍    | 301/550 [05:05<04:13,  1.02s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 5 - Current Pareto front scores:\n",
            "-1\t0.786889347117\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.35000000000000003, RandomForestClassifier__min_samples_leaf=5, RandomForestClassifier__min_samples_split=17, RandomForestClassifier__n_estimators=100)\n",
            "\n",
            "Periodic pipeline was not saved, probably saved before...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  55%|█████▍    | 301/550 [05:06<05:03,  1.22s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  55%|█████▍    | 301/550 [05:08<05:03,  1.22s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  55%|█████▍    | 301/550 [05:10<05:03,  1.22s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  55%|█████▍    | 301/550 [05:19<05:03,  1.22s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  55%|█████▌    | 303/550 [05:19<11:33,  2.81s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  64%|██████▍   | 351/550 [06:24<04:23,  1.33s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 6 - Current Pareto front scores:\n",
            "-1\t0.786889347117\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.35000000000000003, RandomForestClassifier__min_samples_leaf=5, RandomForestClassifier__min_samples_split=17, RandomForestClassifier__n_estimators=100)\n",
            "\n",
            "Periodic pipeline was not saved, probably saved before...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  64%|██████▍   | 351/550 [06:24<03:28,  1.05s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  64%|██████▍   | 351/550 [06:26<03:28,  1.05s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  64%|██████▍   | 351/550 [06:27<03:28,  1.05s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  64%|██████▍   | 351/550 [06:31<03:28,  1.05s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  64%|██████▍   | 351/550 [06:33<03:28,  1.05s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 401/550 [08:04<04:03,  1.64s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 7 - Current Pareto front scores:\n",
            "-1\t0.786889347117\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.35000000000000003, RandomForestClassifier__min_samples_leaf=5, RandomForestClassifier__min_samples_split=17, RandomForestClassifier__n_estimators=100)\n",
            "\n",
            "Periodic pipeline was not saved, probably saved before...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 401/550 [08:05<03:34,  1.44s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 401/550 [08:05<03:34,  1.44s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 401/550 [08:15<03:34,  1.44s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 401/550 [08:19<03:34,  1.44s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 401/550 [08:19<03:34,  1.44s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 402/550 [08:21<14:12,  5.76s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  82%|████████▏ | 451/550 [09:29<02:23,  1.45s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 8 - Current Pareto front scores:\n",
            "-1\t0.786889347117\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.35000000000000003, RandomForestClassifier__min_samples_leaf=5, RandomForestClassifier__min_samples_split=17, RandomForestClassifier__n_estimators=100)\n",
            "\n",
            "Periodic pipeline was not saved, probably saved before...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  82%|████████▏ | 451/550 [09:32<02:12,  1.34s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  91%|█████████ | 501/550 [10:56<00:58,  1.19s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 9 - Current Pareto front scores:\n",
            "-1\t0.786889347117\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.35000000000000003, RandomForestClassifier__min_samples_leaf=5, RandomForestClassifier__min_samples_split=17, RandomForestClassifier__n_estimators=100)\n",
            "\n",
            "Periodic pipeline was not saved, probably saved before...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  91%|█████████ | 501/550 [10:57<00:56,  1.15s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  91%|█████████ | 501/550 [11:04<00:56,  1.15s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  91%|█████████ | 501/550 [11:07<00:56,  1.15s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  91%|█████████ | 501/550 [11:07<00:56,  1.15s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  91%|█████████ | 501/550 [11:10<00:56,  1.15s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 10 - Current Pareto front scores:\n",
            "-1\t0.786889347117\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.35000000000000003, RandomForestClassifier__min_samples_leaf=5, RandomForestClassifier__min_samples_split=17, RandomForestClassifier__n_estimators=100)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
              "        disable_update_check=False, early_stop=None, generations=10,\n",
              "        max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
              "        mutation_rate=0.9, n_jobs=-1, offspring_size=None,\n",
              "        periodic_checkpoint_folder='periodic_checkpoint_folder',\n",
              "        population_size=50, random_state=23, scoring='accuracy',\n",
              "        subsample=1.0, use_dask=False, verbosity=3, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "cAnbdjkJZvpl",
        "colab_type": "code",
        "outputId": "e2180a8c-3aa8-4d73-df22-7a825ddb8be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "tpot.score(X_test, y_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7586206896551724"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "fGxjvnm6fgZ8",
        "colab_type": "code",
        "outputId": "e87ad55f-82d8-4591-8a2b-e200019e7926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "cell_type": "code",
      "source": [
        "# Winning pipelines\n",
        "print(tpot.fitted_pipeline_)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pipeline(memory=None,\n",
            "     steps=[('randomforestclassifier', RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features=0.35, max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=5, min_samples_split=17,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yngce-6nf4nW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# export best model to python file\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "tpot.export('tpot_best_model.py')\n",
        "\n",
        "files.download('tpot_best_model.py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s-jIoT6QgBl_",
        "colab_type": "code",
        "outputId": "b27557df-36b0-4869-a6cd-0d3dc2eafee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "y_predict = tpot.predict(X_test)\n",
        "\n",
        "# Probability of malignant tissue produced by the model\n",
        "y_prob = [probs[1] for probs in tpot.predict_proba(X_test)]\n",
        "\n",
        "#Accuracy on test set\n",
        "print(\"Test accuracy: %s\"%(accuracy_score(y_test, y_predict).round(2)))\n",
        "\n",
        "# Confusion matrix test set\n",
        "pd.DataFrame(\n",
        "    confusion_matrix(y_test, y_predict),\n",
        "    columns=['Predicted NO', 'Predicted YES'],\n",
        "    index=['Actual NO', 'Actual YES']\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.76\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted NO</th>\n",
              "      <th>Predicted YES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual NO</th>\n",
              "      <td>60</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual YES</th>\n",
              "      <td>12</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Predicted NO  Predicted YES\n",
              "Actual NO             60             16\n",
              "Actual YES            12             28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "iwfggAmSgDq-",
        "colab_type": "code",
        "outputId": "bafb138e-3505-4bdb-ee0b-a2f656054748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        }
      },
      "cell_type": "code",
      "source": [
        "# Compute area under the curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "#Set default figure size\n",
        "plt.rcParams['figure.figsize'] = (8,8)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title(\"Title\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAHvCAYAAACmMv3vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhRBCCCPyb+QI8M5Fpui9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3b09525a10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}