{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically selecting a naive model to use as a benchmark\n",
    "\n",
    "forecast-tools provides a `auto_naive` function that uses point-forecast cross validation to select the 'best' naive model to use as a benchmark.  \n",
    "\n",
    "The function tests all of the naive `Forecast` methods.\n",
    "\n",
    "This notebook covers how to use `auto_naive` and also how to trouble shoot it use if there are conflicts between parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from forecast_tools.datasets import load_emergency_dept\n",
    "from forecast_tools.model_selection import auto_naive                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function auto_naive in module forecast_tools.model_selection:\n",
      "\n",
      "auto_naive(y_train, horizon=1, seasonal_period=1, min_train_size='auto', method='cv', step=1, window_size='auto', metric='mae')\n",
      "    Automatic selection of the 'best' naive benchmark on a 'single' series\n",
      "    \n",
      "    The selection process uses out-of-sample cv performance.\n",
      "    \n",
      "    By default auto_naive uses cross validation to estimate the mean\n",
      "    point forecast peformance of all naive methods.  It selects the method\n",
      "    with the lowest point forecast metric on average.\n",
      "    \n",
      "    If there is limited data for training a basic holdout sample could be\n",
      "    used.\n",
      "    \n",
      "    Dev note: the plan is to update this to work with multiple series.\n",
      "    It would be best to use MASE for multiple series comparison.\n",
      "    \n",
      "    Parameters:\n",
      "    ----------\n",
      "    y_train: array-like\n",
      "        training data.  typically in a pandas.Series, pandas.DataFrame\n",
      "        or numpy.ndarray format.\n",
      "    \n",
      "    horizon: int, optional (default=1)\n",
      "        Forecast horizon.\n",
      "    \n",
      "    seasonal_period: int, optional (default=1)\n",
      "        Frequency of the data.  E.g. 7 for weekly pattern, 12 for monthly\n",
      "        365 for daily.\n",
      "    \n",
      "    min_train_size: int or str, optional (default='auto')\n",
      "        The size of the initial training set (if method=='ro' or 'sw').\n",
      "        If 'auto' then then min_train_size is set to len(y_train) // 3\n",
      "        If main_train_size='auto' and method='holdout' then\n",
      "        min_train_size = len(y_train) - horizon.\n",
      "    \n",
      "    method: str, optional (default='cv')\n",
      "        out of sample selection method.\n",
      "        'ro' - rolling forecast origin\n",
      "        'sw' - sliding window\n",
      "        'cv' - scores from both ro and sw\n",
      "        'holdout' - single train/test split\n",
      "         Methods'ro' and 'sw' are similar, however, sw has a fixed\n",
      "         window_size and drops older data from training.\n",
      "    \n",
      "    step: int, optional (default=1)\n",
      "        The stride/step of the cross-validation. I.e. the number\n",
      "        of observations to move forward between folds.\n",
      "    \n",
      "    window_size: str or int, optional (default='auto')\n",
      "        The window_size if using sliding window cross validation\n",
      "        When 'auto' and method='sw' then\n",
      "        window_size=len(y_train) // 3\n",
      "    \n",
      "    metric: str, optional (default='mae')\n",
      "        The metric to measure out of sample accuracy.\n",
      "        Options: mase, mae, mape, smape, mse, rmse, me.\n",
      "    \n",
      "    Returns:\n",
      "    --------\n",
      "    dict\n",
      "        'model': baseline.Forecast\n",
      "        f'{metric}': float\n",
      "    \n",
      "        Contains the model and its CV performance.\n",
      "    \n",
      "    Raises:\n",
      "    -------\n",
      "    ValueError\n",
      "        For invalid method, metric, window_size parameters\n",
      "    \n",
      "    See Also:\n",
      "    --------\n",
      "    forecast_tools.baseline.Naive1\n",
      "    forecast_tools.baseline.SNaive\n",
      "    forecast_tools.baseline.Drift\n",
      "    forecast_tools.baseline.Average\n",
      "    forecast_tools.baseline.EnsembleNaive\n",
      "    forecast_tools.baseline.baseline_estimators\n",
      "    forecast_tools.model_selection.rolling_forecast_origin\n",
      "    forecast_tools.model_selection.sliding_window\n",
      "    forecast_tools.model_selection.mase_cross_validation_score\n",
      "    forecast_tools.metrics.mean_absolute_scaled_error\n",
      "    \n",
      "    Examples:\n",
      "    ---------\n",
      "    Measuring MAE and taking the best method using both\n",
      "    rolling origin and sliding window cross validation\n",
      "    of a 56 day forecast.\n",
      "    \n",
      "    >>> from forecast_tools.datasets import load_emergency_dept\n",
      "    >>> y_train = load_emergency_dept\n",
      "    >>> best = auto_naive(y_train, seasonal_period=7, horizon=56)\n",
      "    >>> best\n",
      "    {'model': Average(), 'mae': 19.63791579700355}\n",
      "    \n",
      "    \n",
      "    Take a step of 7 days between cv folds.\n",
      "    \n",
      "    >>> from forecast_tools.datasets import load_emergency_dept\n",
      "    >>> y_train = load_emergency_dept\n",
      "    >>> best = auto_naive(y_train, seasonal_period=7, horizon=56,\n",
      "        ...               step=7)\n",
      "    >>> best\n",
      "    {'model': Average(), 'mae': 19.675635558539383}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(auto_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = load_emergency_dept()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the best naive model for a h-step horizon of 7 days.\n",
    "\n",
    "Let's select a method for the emergency deparment daily level to predict 7 days ahead.  By default the function using the **mean absolute error** to evaluate forecast accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': Average(), 'mae': 19.679856211931035}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = auto_naive(y_train, horizon=7, seasonal_period=7)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([221.06395349, 221.06395349, 221.06395349, 221.06395349,\n",
       "       221.06395349, 221.06395349, 221.06395349])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = best['model'].fit_predict(y_train, horizon=7)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a different forecasting error metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': Average(), 'mape': 8.69955926909263}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = auto_naive(y_train, horizon=7, seasonal_period=7, metric='mape')\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a single train-test split when data are limited.\n",
    "\n",
    "If your forecast horizon means that h-step cross-validation is infeasible then you can automatically select using a single holdout sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': Average(), 'mae': 30.182280627384486}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = auto_naive(y_train, horizon=7, seasonal_period=7, method='holdout')\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trouble shooting use of `auto_naive`\n",
    "\n",
    "**Problem 1:** Training data is shorter than the `min_train_size` + `horizon`\n",
    "\n",
    "For any validation to take place, including a simple holdout - the time series used must allow at least one train test split to take place.  This can be a problem when seasonal_period is set to a length similar to the length of the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a synthetic daily time series of exactly one year in length.\n",
    "y_train = np.random.randint(100, 250, size=365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set seasonal period to `seasonal_period=365` (the length of the time series) and `horizon=7`.\n",
    "\n",
    "We will also manually set `min_train_size=365`\n",
    "\n",
    "This will generate a `ValueError` reporting that the \"The training data is shorter than min_train_size + horizon  No validation can be performed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The training data is shorter than min_train_size=365 + horizon=7 No validation can be performed. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d9dc4e172979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m best = auto_naive(y_train, horizon=7, seasonal_period=365, method='ro', \n\u001b[0m\u001b[1;32m      2\u001b[0m                   min_train_size=365, metric='mae')\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/forecast_dev/lib/python3.8/site-packages/forecast_tools/model_selection.py\u001b[0m in \u001b[0;36mauto_naive\u001b[0;34m(y_train, horizon, seasonal_period, min_train_size, method, step, window_size, metric)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"The training data is shorter than {min_train_size=} + {horizon=}\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m\" No validation can be performed. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmin_train_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mseasonal_period\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cv'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Seasonal period is longer than the minimum training size for\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The training data is shorter than min_train_size=365 + horizon=7 No validation can be performed. "
     ]
    }
   ],
   "source": [
    "best = auto_naive(y_train, horizon=7, seasonal_period=365, method='ro', \n",
    "                  min_train_size=365, metric='mae')\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A longer time series or a shorter seasonal period will fix this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': Average(), 'mae': 43.29549902152642}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a longer synthetic time series.\n",
    "y_train = np.random.randint(100, 250, size=365+7)\n",
    "best = auto_naive(y_train, horizon=7, seasonal_period=365, method='ro', \n",
    "                  min_train_size=365, metric='mae')\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': Average(), 'mae': 37.50786553941686}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a shorter seasonal period and minimum training size\n",
    "y_train = np.random.randint(100, 250, size=365)\n",
    "best = auto_naive(y_train, horizon=7, seasonal_period=7, method='ro', \n",
    "                  min_train_size=7, metric='mae')\n",
    "\n",
    "best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
